{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prototype: MLOps CDK Pipeline Model Quality Monitor (SageMaker SDK)\n",
    "\n",
    "## Overview\n",
    "The purpose of this note book is to formulate and test the data preparation and setup for the Model Quality Monitor Baseline as it relates to the MLOps CDK Pipeline MKV testing. The notebopok uses the SageMaker SDK to verify that the solution works first, before portgint the functionality to a Lambda Function.\n",
    "\n",
    "><div class=\"alert alert-block alert-info\"><b>NOTE: </b> The code is roughly based on the official <a href=\"https://github.com/aws/amazon-sagemaker-examples/blob/master/sagemaker_model_monitor/model_quality/model_quality_churn_sdk.ipynb\"><b>SageMaker Example</b></a></div> \n",
    "\n",
    "## Section 1 - Setup\n",
    "\n",
    "### Section 1.1 - Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta, timezone\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import boto3\n",
    "from time import sleep\n",
    "from threading import Thread\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sagemaker import get_execution_role, session, Session, image_uris\n",
    "from sagemaker.s3 import S3Downloader, S3Uploader\n",
    "from sagemaker.processing import ProcessingJob\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.model_monitor import DataCaptureConfig\n",
    "\n",
    "session = Session()\n",
    "ssm = boto3.client('ssm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1.2 - AWS Region and IAM Role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Execution role\n",
    "role = get_execution_role()\n",
    "print(\"RoleArn:\", role)\n",
    "\n",
    "region = session.boto_region_name\n",
    "print(\"Region:\", region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1.3 - Bucket and Prefixes\n",
    "\n",
    "For the sake of testing, we will leverage the SageMaker Production Endpoint and the Production Logs S3 Bucket.\n",
    "\n",
    "><div class=\"alert alert-block alert-warning\"><b>NOTE: </b>The following section assumes that the CDK Pipeline has already been deployed into production.</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the Endpoint name\n",
    "model_name = 'abalone'\n",
    "endpoint_name = f'{model_name}-prod-endpoint'\n",
    "\n",
    "# Get the Baseline Data URI SSM Parameter\n",
    "parameter_name = 'BaselineDataUri'\n",
    "baseline_data_uri = ssm.get_parameter(Name=parameter_name)['Parameter']['Value']\n",
    "\n",
    "# Leverage the existing \"Prod\" parameters\n",
    "# Production Logs bucket name\n",
    "bucket = 'proddeploymentstage-prodappl-logss3bucket004b0f70-3nv3l2whchah'\n",
    "\n",
    "# S3 Prefixes\n",
    "data_capture_prefix = 'endpoint-data-capture'\n",
    "reports_prefix = 'reports'\n",
    "\n",
    "# S3 URIs\n",
    "s3_capture_uri = f's3://{bucket}/{data_capture_prefix}'\n",
    "s3_ground_truth_uri = f's3://{bucket}/ground-truth-data/{datetime.now():%Y-%m-%d-%H-%M-%S}'\n",
    "s3_report_uri = f's3://{bucket}/{reports_prefix}'\n",
    "\n",
    "# Get the Model Monitor URI\n",
    "monitor_image_uri = image_uris.retrieve(framework='model-monitor', region=region)\n",
    "\n",
    "# Print these outputs to remember\n",
    "print(f'Baseline Data Location: {baseline_data_uri}')\n",
    "print(f'Model Monitor Image URI: {monitor_image_uri}')\n",
    "print(f'Endpoint Data Capture Location: {s3_capture_uri}')\n",
    "print(f'Ground Truth Data Location: {s3_ground_truth_uri}')\n",
    "print(f'Model Quality Report Location: {s3_report_uri}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1.4 - Download the Baseline Dataset\n",
    "\n",
    "The baseline dtaset should have already been created by the \"Evaluation Step\" of the pipeline, with the location stored as an SSM parameter. Next we download this baseline data and use it to suggest our baseline constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test downloading the baseline data\n",
    "S3Downloader.download(baseline_data_uri, '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the data\n",
    "!head baseline.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 2 - Generate the baseline for model quality performance\n",
    "\n",
    "### Section 2.1 - Create a SageMaker Predictor object for the Production Endpoint\n",
    "\n",
    "><div class=\"alert alert-block alert-warning\"><b>NOTE: </b>The following uses the SageMaker SDK <em>Predicor</em> along with the <em>CSVSerializer</em>. It is unknown at this stage how this will translate to the the funciton call in the Lambda Function. Additioanlly, it is unknown at this point of creating a Baseline Suggestion actually requires the Endpoint.</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a `Predictor` to callthe endpoint\n",
    "from sagemaker.predictor import Predictor\n",
    "predictor = Predictor(endpoint_name=endpoint_name, sagemaker_session=session, serializer=CSVSerializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.2 - Setup S3 locations for capturing baseline results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the locations for capturing the baseline results\n",
    "baseline_prefix = 'baselining'\n",
    "baseline_data_prefix = baseline_prefix + '/data'\n",
    "baseline_results_prefix = baseline_prefix + '/results'\n",
    "\n",
    "baseline_data_uri = f's3://{bucket}/{baseline_data_prefix}'\n",
    "baseline_results_uri = f's3://{bucket}/{baseline_results_prefix}'\n",
    "print(f'Baseline data uri: {baseline_data_uri}')\n",
    "print(f'Baseline results uri: {baseline_results_uri}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_dataset_uri = S3Uploader.upload('baseline.csv', baseline_data_uri)\n",
    "baseline_dataset_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.3 - Create the Baseline Suggesiton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model_monitor import ModelQualityMonitor\n",
    "from sagemaker.model_monitor import EndpointInput\n",
    "from sagemaker.model_monitor.dataset_format import DatasetFormat\n",
    "\n",
    "#Create the model quality monitoring object\n",
    "model_quality_monitor = ModelQualityMonitor(\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    volume_size_in_gb=20,\n",
    "    max_runtime_in_seconds=1800,\n",
    "    sagemaker_session=session\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Name of the model quality baseline job\n",
    "baseline_job_name = f\"abalone-baseline-job-{datetime.utcnow():%Y-%m-%d-%H%M}\"\n",
    "baseline_job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Execute the baseline suggestion job. \n",
    "#You will specify problem type, in this case Binary Classification, and provide other required attributes.\n",
    "job = model_quality_monitor.suggest_baseline(\n",
    "    job_name=baseline_job_name,\n",
    "    baseline_dataset=baseline_dataset_uri,\n",
    "    dataset_format=DatasetFormat.csv(header=True),\n",
    "    output_s3_uri = baseline_results_uri,\n",
    "    problem_type='Regression',\n",
    "    inference_attribute= \"prediction\",\n",
    "    ground_truth_attribute= \"label\"\n",
    ")\n",
    "job.wait(logs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.4 - Review the Results\n",
    "\n",
    "#### Baseline Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_job = model_quality_monitor.latest_baselining_job\n",
    "binary_metrics = baseline_job.baseline_statistics().body_dict['regression_metrics']\n",
    "pd.json_normalize(binary_metrics).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(baseline_job.suggested_constraints().body_dict[\"regression_constraints\"]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 3 - Conclusion\n",
    "\n",
    "So basicall, fromt he constraints that are generated, the Model Monitor makes tracks to make sure that the $R^2$ score doesn't drop below $0.617261$. Since the main evaluation metric for this use case is leveraging the $RMSE$, this will be the the easiest determinator for concept drift in model quality. So if the Model Monitor picks up that the contraints are exceeding $2.04811$ (which incidently is simialr to the evaluation threshold of $2.1$ in the Model Framing Example), then this will cause the alert."
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
