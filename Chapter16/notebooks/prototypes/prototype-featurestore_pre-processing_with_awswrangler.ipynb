{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-work `preprocess.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "def get_featurestore_params(feature_group_name):\n",
    "    try:\n",
    "        sm = boto3.client('sagemaker')\n",
    "        response = sm.describe_feature_group(\n",
    "            FeatureGroupName='AbaloneFeatureGroup'\n",
    "        )\n",
    "        return response['OfflineStoreConfig']['DataCatalogConfig']['Database'], response['OfflineStoreConfig']['DataCatalogConfig']['TableName']\n",
    "    except ClientError as e:\n",
    "        error_message = e.response['Error']['Message']\n",
    "        # raise Exception(error_message)\n",
    "        print(error_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = sm.list_feature_groups(\n",
    "    NameContains='fuck'\n",
    ")\n",
    "if response['FeatureGroupSummaries'] == []:\n",
    "    print(\"Not Found\")\n",
    "else:\n",
    "    featuregroup_name = response['FeatureGroupSummaries'][0]['FeatureGroupName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database, table = get_featurestore_params(featuregroup_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "subprocess.call([sys.executable, \"-m\", \"pip\", \"install\", \"pyarrow==2\", \"awswrangler==2.7.0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import awswrangler as wr\n",
    "\n",
    "table_cols = [\n",
    "    'rings',\n",
    "    'length',\n",
    "    'diameter',\n",
    "    'height',\n",
    "    'whole_weight',\n",
    "    'shucked_weight',\n",
    "    'viscera_weight',\n",
    "    'shell_weight',\n",
    "    'sex_F',\n",
    "    'sex_I',\n",
    "    'sex_M'\n",
    "]\n",
    "query_string = f'SELECT {\",\".join(header)} FROM \"{table}\"'\n",
    "#wr.athena.read_sql_query(f'SELECT \"{\",\".join(header)}\" FROM \"{table}\"', database=database, ctas_approach=False)\n",
    "featurestore_df = wr.athena.read_sql_query(query_string, database=database, ctas_approach=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurestore_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import requests\n",
    "import tempfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "sm = boto3.client('sagemaker')\n",
    "\n",
    "# Since we get a headerless CSV file we specify the column names here.\n",
    "feature_columns_names = [\n",
    "    'sex',\n",
    "    'length',\n",
    "    'diameter',\n",
    "    'height',\n",
    "    'whole_weight',\n",
    "    'shucked_weight',\n",
    "    'viscera_weight',\n",
    "    'shell_weight',\n",
    "]\n",
    "label_column = 'rings'\n",
    "\n",
    "feature_columns_dtype = {\n",
    "    'sex': str,\n",
    "    'length': np.float64,\n",
    "    'diameter': np.float64,\n",
    "    'height': np.float64,\n",
    "    'whole_weight': np.float64,\n",
    "    'shucked_weight': np.float64,\n",
    "    'viscera_weight': np.float64,\n",
    "    'shell_weight': np.float64\n",
    "}\n",
    "label_column_dtype = {'rings': np.float64}\n",
    "\n",
    "\n",
    "def confirm_featurestore(model_name):\n",
    "    response = sm.list_feature_groups(\n",
    "        NameContains=model_name\n",
    "    )\n",
    "    if response['FeatureGroupSummaries'] == []:\n",
    "        return None\n",
    "    else:\n",
    "        return response['FeatureGroupSummaries'][0]['FeatureGroupName']\n",
    "\n",
    "\n",
    "def get_featurestore_params(feature_group_name):\n",
    "    try:\n",
    "        response = sm.describe_feature_group(\n",
    "            FeatureGroupName=feature_group_name\n",
    "        )\n",
    "        return response['OfflineStoreConfig']['DataCatalogConfig']['Database'], response['OfflineStoreConfig']['DataCatalogConfig']['TableName']\n",
    "    except ClientError as e:\n",
    "        error_message = e.response['Error']['Message']\n",
    "        raise Exception(error_message)\n",
    "#         print(error_message)\n",
    "\n",
    "def merge_two_dicts(x, y):\n",
    "    z = x.copy()\n",
    "    z.update(y)\n",
    "    return z\n",
    "\n",
    "\n",
    "base_dir = './'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    f'{base_dir}/abalone.csv',\n",
    "    header=None, \n",
    "    names=feature_columns_names + [label_column],\n",
    "    dtype=merge_two_dicts(feature_columns_dtype, label_column_dtype)\n",
    ")\n",
    "\n",
    "numeric_features = list(feature_columns_names)\n",
    "numeric_features.remove('sex')\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "categorical_features = ['sex']\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "    \n",
    "y = df.pop('rings')\n",
    "X_pre = preprocess.fit_transform(df)\n",
    "y_pre = y.to_numpy().reshape(len(y), 1)\n",
    "X = np.concatenate((y_pre, X_pre), axis=1)\n",
    "np.random.shuffle(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# featurestore_name = confirm_featurestore(os.environ['MODEL_NAME'])\n",
    "featurestore_name = confirm_featurestore('abalone')\n",
    "if featurestore_name != None:\n",
    "    import subprocess\n",
    "    import sys\n",
    "    \n",
    "    subprocess.call([sys.executable, \"-m\", \"pip\", \"install\", \"pyarrow==2\", \"awswrangler==2.7.0\"])\n",
    "    database, table = get_featurestore_params(featurestore_name)\n",
    "    \n",
    "    import awswrangler as wr\n",
    "    \n",
    "    table_cols = [\n",
    "        'rings',\n",
    "        'length',\n",
    "        'diameter',\n",
    "        'height',\n",
    "        'whole_weight',\n",
    "        'shucked_weight',\n",
    "        'viscera_weight',\n",
    "        'shell_weight',\n",
    "        'sex_F',\n",
    "        'sex_I',\n",
    "        'sex_M'\n",
    "    ]\n",
    "    \n",
    "    query_string = f'SELECT {\",\".join(table_cols)} FROM \"{table}\"'\n",
    "    featurestore_df = wr.athena.read_sql_query(query_string, database=database, ctas_approach=False)\n",
    "    raw_df = pd.DataFrame(X, columns=table_cols)\n",
    "    X = pd.concat([raw_df, featurestore_df]).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.        , -0.57455813, -0.33137077, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [11.        ,  0.6329849 ,  0.5252424 , ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [ 5.        , -1.44898585, -1.49031801, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 6.        , -1.21593601, -1.60478947, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [ 6.        , -1.9763402 , -0.82727874, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [14.        ,  0.13897866,  0.40168949, ...,  1.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (80%, 15%, 5%) train/validation/test split\n",
    "training, validation, testing = np.split(X, [int(.8*len(X)), int(.95*len(X))])\n",
    "header = [\n",
    "    'rings',\n",
    "    'length',\n",
    "    'diameter',\n",
    "    'height',\n",
    "    'whole_weight',\n",
    "    'shucked_weight',\n",
    "    'viscera_weight',\n",
    "    'shell_weight',\n",
    "    'sex_F',\n",
    "    'sex_I',\n",
    "    'sex_M'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the training and testing datasets for the SageMaker training Job\n",
    "pd.DataFrame(training).to_csv(f'{base_dir}/training.csv', header=False, index=False)\n",
    "pd.DataFrame(validation).to_csv(f'{base_dir}/validation.csv', header=False, index=False)\n",
    "pd.DataFrame(testing).to_csv(f'{base_dir}/testing.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
